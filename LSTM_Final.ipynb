{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zauSMbnC1mS4",
        "outputId": "b6ba7b7d-de14-4da8-f2b3-4142bfaf4a0a"
      },
      "source": [
        "!pip install tensorflow-gpu\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.34.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEuNbyh62LcB"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import datetime\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Ppxgjl2Loc",
        "outputId": "09858161-a81b-4531-c8b6-83fc867cdf3c"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Dataset/train.csv\")\r\n",
        "store_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/store.csv\")\r\n",
        "df = pd.merge(df, store_df, how='inner', on='Store')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ExVQNGyO2LzV",
        "outputId": "7d8abf12-249a-476a-fa32-59a86fa15a9a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Date</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Customers</th>\n",
              "      <th>Open</th>\n",
              "      <th>Promo</th>\n",
              "      <th>StateHoliday</th>\n",
              "      <th>SchoolHoliday</th>\n",
              "      <th>StoreType</th>\n",
              "      <th>Assortment</th>\n",
              "      <th>CompetitionDistance</th>\n",
              "      <th>CompetitionOpenSinceMonth</th>\n",
              "      <th>CompetitionOpenSinceYear</th>\n",
              "      <th>Promo2</th>\n",
              "      <th>Promo2SinceWeek</th>\n",
              "      <th>Promo2SinceYear</th>\n",
              "      <th>PromoInterval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>5263</td>\n",
              "      <td>555</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-07-30</td>\n",
              "      <td>5020</td>\n",
              "      <td>546</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2015-07-29</td>\n",
              "      <td>4782</td>\n",
              "      <td>523</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-07-28</td>\n",
              "      <td>5011</td>\n",
              "      <td>560</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-07-27</td>\n",
              "      <td>6102</td>\n",
              "      <td>612</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  DayOfWeek        Date  ...  Promo2SinceWeek  Promo2SinceYear  PromoInterval\n",
              "0      1          5  2015-07-31  ...              NaN              NaN            NaN\n",
              "1      1          4  2015-07-30  ...              NaN              NaN            NaN\n",
              "2      1          3  2015-07-29  ...              NaN              NaN            NaN\n",
              "3      1          2  2015-07-28  ...              NaN              NaN            NaN\n",
              "4      1          1  2015-07-27  ...              NaN              NaN            NaN\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH2wWXoU2_Ev",
        "outputId": "c66c2315-4410-4f70-d002-84aae0c7f012"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1017209 entries, 0 to 1017208\n",
            "Data columns (total 18 columns):\n",
            " #   Column                     Non-Null Count    Dtype  \n",
            "---  ------                     --------------    -----  \n",
            " 0   Store                      1017209 non-null  int64  \n",
            " 1   DayOfWeek                  1017209 non-null  int64  \n",
            " 2   Date                       1017209 non-null  object \n",
            " 3   Sales                      1017209 non-null  int64  \n",
            " 4   Customers                  1017209 non-null  int64  \n",
            " 5   Open                       1017209 non-null  int64  \n",
            " 6   Promo                      1017209 non-null  int64  \n",
            " 7   StateHoliday               1017209 non-null  object \n",
            " 8   SchoolHoliday              1017209 non-null  int64  \n",
            " 9   StoreType                  1017209 non-null  object \n",
            " 10  Assortment                 1017209 non-null  object \n",
            " 11  CompetitionDistance        1014567 non-null  float64\n",
            " 12  CompetitionOpenSinceMonth  693861 non-null   float64\n",
            " 13  CompetitionOpenSinceYear   693861 non-null   float64\n",
            " 14  Promo2                     1017209 non-null  int64  \n",
            " 15  Promo2SinceWeek            509178 non-null   float64\n",
            " 16  Promo2SinceYear            509178 non-null   float64\n",
            " 17  PromoInterval              509178 non-null   object \n",
            "dtypes: float64(5), int64(8), object(5)\n",
            "memory usage: 147.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDTPOXro2_PM"
      },
      "source": [
        "#Data Preprocessing\r\n",
        "df = df.drop(df[df.Open == 0].index)\r\n",
        "df = df.drop(df[df.Sales == 0].index)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLYUoGH2_Ro"
      },
      "source": [
        "# Convert for time series\r\n",
        "df['Date'] = df['Date'].astype('datetime64[ns]')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqZ8pT5j2_Tw",
        "outputId": "70d709f8-7158-4b72-d622-33f9d3803114"
      },
      "source": [
        "store_df.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Store                          0\n",
              "StoreType                      0\n",
              "Assortment                     0\n",
              "CompetitionDistance            3\n",
              "CompetitionOpenSinceMonth    354\n",
              "CompetitionOpenSinceYear     354\n",
              "Promo2                         0\n",
              "Promo2SinceWeek              544\n",
              "Promo2SinceYear              544\n",
              "PromoInterval                544\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRNGFVp12_WK"
      },
      "source": [
        "df['CompetitionDistance'].fillna(store_df['CompetitionDistance'].median(), inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQiYUW-O2_Ye"
      },
      "source": [
        "df.fillna(0, inplace = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WspLQPtm2_aw",
        "outputId": "25dc3ad7-69ec-4571-9f90-30e33fa8aa55"
      },
      "source": [
        "df['StateHoliday'] = df.StateHoliday.replace([0, '0'], np.nan)\r\n",
        "df.StateHoliday.unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'a', 'b', 'c'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuZ8uhg-2_dU"
      },
      "source": [
        "dummy_columns = ['StoreType', 'Assortment', 'StateHoliday']\r\n",
        "df = pd.get_dummies(df, columns=dummy_columns)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBqMcOwl2_gu",
        "outputId": "d35a5883-b6e9-4621-af1a-66ab59c07304"
      },
      "source": [
        "#Splitting the Date as Day, month and year and adding 3 new columns\r\n",
        "df['Day'] = df['Date'].dt.day\r\n",
        "df['Month'] = df['Date'].dt.month\r\n",
        "df['Year'] = df['Date'].dt.year\r\n",
        "df['Weekofyear'] = df['Date'].dt.weekofyear"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyW7s_TZ3ck2"
      },
      "source": [
        "#How long the competition has been open\r\n",
        "df['CompetitionOpen'] = 12 * (df.Year - df.CompetitionOpenSinceYear) + (df.Month - df.CompetitionOpenSinceMonth)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktg-TwmZ3cnQ"
      },
      "source": [
        "#How long the promo has been running\r\n",
        "df['PromoOpen'] = 12 * (df.Year - df.Promo2SinceYear) + (df.Weekofyear - df.Promo2SinceWeek) / 4.0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oo0HmXM3cpp"
      },
      "source": [
        "df = df.drop(columns=['Weekofyear','Promo2SinceWeek', 'CompetitionOpenSinceMonth', 'Promo2SinceYear', 'CompetitionOpenSinceYear', 'Open', 'PromoInterval'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE7PJB9o3cr-"
      },
      "source": [
        "#replace competitiondistance with furthest variable\r\n",
        "df['CompetitionDistance'] = df.CompetitionDistance.replace(np.nan, df['CompetitionDistance'].max())\r\n",
        "                                                           \r\n",
        "#Competittion Open - use mean\r\n",
        "df['CompetitionOpen'] = df.CompetitionOpen.replace(np.nan, df['CompetitionOpen'].max())\r\n",
        "\r\n",
        "#PromoOpen - recode missing as 0\r\n",
        "df['PromoOpen'] = df.PromoOpen.replace(np.nan, 0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9ebNOcJ3cuP",
        "outputId": "1c85c496-0355-4ff3-d8f9-735276c4aa54"
      },
      "source": [
        "from scipy.stats import zscore\r\n",
        "\r\n",
        "z_scores = np.abs(zscore(df.Sales))\r\n",
        "z_scores"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54544483, 0.62373562, 0.70041548, ..., 0.77838407, 0.85667486,\n",
              "       1.04998543])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noERYILO3cwd",
        "outputId": "0c6f4eec-cb12-48f2-f0da-cf1be4fa1252"
      },
      "source": [
        "removed_df = df[z_scores < 3]\r\n",
        "print('Removed data', len(df) - len(removed_df))\r\n",
        "df = removed_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed data 13443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTCGAjYq3cy4"
      },
      "source": [
        "X = df.drop(columns=['Date','Sales','Customers','Store','StateHoliday_b','StateHoliday_c'])\r\n",
        "Y = df['Sales']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGVYP1l-3c07",
        "outputId": "65a0ae1e-993e-4784-d2e8-4cb66e92f15d"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "scaled_X = scaler.fit_transform(X)\r\n",
        "scaled_X"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.85442228,  1.12330986,  2.04438985, ...,  1.50221827,\n",
              "        -0.68066285,  1.00770216],\n",
              "       [ 0.27291095,  1.12330986,  2.04438985, ...,  1.50221827,\n",
              "        -0.68066285,  1.00770216],\n",
              "       [-0.30860038,  1.12330986,  2.04438985, ...,  1.50221827,\n",
              "        -0.68066285,  1.00770216],\n",
              "       ...,\n",
              "       [ 0.85442228, -0.89022632,  2.04438985, ..., -1.07021472,\n",
              "         1.46364546, -0.99514049],\n",
              "       [ 0.27291095, -0.89022632,  2.04438985, ..., -1.07021472,\n",
              "         1.46364546, -0.99514049],\n",
              "       [-0.30860038, -0.89022632,  2.04438985, ..., -1.07021472,\n",
              "         1.46364546, -0.99514049]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV5jGinD3c3Q",
        "outputId": "d40f01f7-bc3a-41bc-f88b-a46b02d6c524"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_rest, y_train, y_rest = train_test_split(scaled_X, Y, test_size=0.30)\r\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_rest, y_rest, test_size=0.5)\r\n",
        "print(len(x_train) + len(x_test) + len(x_val) == len(df))\r\n",
        "print(x_train)\r\n",
        "print(x_test)\r\n",
        "x_val"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "[[ 1.43593361 -0.89022632 -0.4891435  ... -1.07021472 -0.6819098\n",
            "  -0.99632078]\n",
            " [ 0.27291095  1.12330986 -0.4891435  ...  0.21600177 -0.6788815\n",
            "  -0.99261427]\n",
            " [ 0.85442228 -0.89022632 -0.4891435  ... -1.07021472  1.4640908\n",
            "  -0.99346325]\n",
            " ...\n",
            " [ 0.85442228 -0.89022632 -0.4891435  ... -1.07021472  1.4640908\n",
            "  -0.99526474]\n",
            " [ 1.43593361 -0.89022632 -0.4891435  ...  0.21600177  1.46560495\n",
            "  -0.99275921]\n",
            " [-0.30860038 -0.89022632 -0.4891435  ... -1.07021472  1.4640908\n",
            "  -0.99572028]]\n",
            "[[ 0.85442228 -0.89022632 -0.4891435  ... -1.07021472 -0.68208794\n",
            "   1.00525876]\n",
            " [-0.30860038  1.12330986 -0.4891435  ...  1.50221827  1.46622842\n",
            "   1.00757792]\n",
            " [-1.47162305  1.12330986 -0.4891435  ...  0.21600177 -0.68858989\n",
            "   1.00685318]\n",
            " ...\n",
            " [-1.47162305 -0.89022632 -0.4891435  ... -1.07021472  1.46364546\n",
            "  -0.99563746]\n",
            " [-1.47162305 -0.89022632 -0.4891435  ... -1.07021472 -0.6863632\n",
            "  -0.99489201]\n",
            " [-0.30860038 -0.89022632  2.04438985 ... -1.07021472  1.46417986\n",
            "  -0.99509908]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.30860038,  1.12330986, -0.4891435 , ...,  0.21600177,\n",
              "        -0.68262235, -0.99489201],\n",
              "       [ 0.27291095,  1.12330986, -0.4891435 , ...,  0.21600177,\n",
              "        -0.6888571 ,  1.00654258],\n",
              "       [-1.47162305,  1.12330986, -0.4891435 , ..., -1.07021472,\n",
              "        -0.68582879, -0.99725259],\n",
              "       ...,\n",
              "       [-0.30860038,  1.12330986,  2.04438985, ...,  0.21600177,\n",
              "         1.46542681,  1.00681177],\n",
              "       [ 0.27291095, -0.89022632,  2.04438985, ...,  1.50221827,\n",
              "        -0.6741609 , -0.99242791],\n",
              "       [-0.89011171,  1.12330986, -0.4891435 , ...,  0.21600177,\n",
              "         1.46542681,  1.0068946 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjkJpiEp3c5m",
        "outputId": "724ab179-106a-4a40-ac52-b9280720b8af"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(581626, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWtKuJIR3-TN",
        "outputId": "b34f5e5c-f4c2-490a-e4c8-20b433738e29"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124634, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C54nkJe3-Vx"
      },
      "source": [
        "#Since the input for a CNN and LSTM should be in 3 dimension, the inputs were reshaped.\r\n",
        "# reshape input to be [samples, time steps, features] which is required for LSTM\r\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\r\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECF00RF13-YT",
        "outputId": "a7bd5235-0709-4771-f497-f8dfd3846b6c"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(581626, 1, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCta93j_3-aa",
        "outputId": "8976b902-b864-4c37-fb32-49b9de1e1128"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124634, 1, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO6mbDex3-dL"
      },
      "source": [
        "#Modelling Part\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras.layers import Dense, Dropout\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEFbELRK3-fE"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(LSTM(16,return_sequences=True,input_shape=(1, 18), activation = 'tanh', kernel_initializer = 'glorot_uniform',\r\n",
        "              kernel_regularizer = 'l2'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(8,return_sequences=True, activation = 'tanh'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(8, activation = 'linear'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4HOZPoz3-iY"
      },
      "source": [
        "model.compile(loss='mean_squared_error',optimizer='adam', metrics = ['mse'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQXyfp-G5gVm",
        "outputId": "a8fb2b0e-d809-4144-faf2-b1d30e9720c4"
      },
      "source": [
        "lstm_model = model.fit(x_train, y_train, epochs=200, verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 19106118.0000 - mse: 19106118.0000\n",
            "Epoch 2/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 7784532.0000 - mse: 7784530.0000\n",
            "Epoch 3/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 7406446.0000 - mse: 7406444.0000\n",
            "Epoch 4/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 7145184.0000 - mse: 7145181.0000\n",
            "Epoch 5/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 6937489.0000 - mse: 6937484.5000\n",
            "Epoch 6/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6784881.0000 - mse: 6784877.0000\n",
            "Epoch 7/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6669318.5000 - mse: 6669315.0000\n",
            "Epoch 8/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6595781.0000 - mse: 6595776.5000\n",
            "Epoch 9/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6553480.5000 - mse: 6553471.0000\n",
            "Epoch 10/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6512256.5000 - mse: 6512251.0000\n",
            "Epoch 11/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6488713.0000 - mse: 6488704.0000\n",
            "Epoch 12/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6467709.0000 - mse: 6467700.5000\n",
            "Epoch 13/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6454356.5000 - mse: 6454348.0000\n",
            "Epoch 14/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6431210.5000 - mse: 6431198.5000\n",
            "Epoch 15/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6410026.5000 - mse: 6410016.5000\n",
            "Epoch 16/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6398278.0000 - mse: 6398267.5000\n",
            "Epoch 17/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6361590.0000 - mse: 6361577.5000\n",
            "Epoch 18/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6370911.5000 - mse: 6370898.0000\n",
            "Epoch 19/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6335115.5000 - mse: 6335101.0000\n",
            "Epoch 20/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6329214.5000 - mse: 6329203.0000\n",
            "Epoch 21/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6304605.5000 - mse: 6304589.0000\n",
            "Epoch 22/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6301273.5000 - mse: 6301260.5000\n",
            "Epoch 23/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6285579.0000 - mse: 6285563.0000\n",
            "Epoch 24/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 6265674.5000 - mse: 6265657.5000\n",
            "Epoch 25/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6249276.0000 - mse: 6249262.5000\n",
            "Epoch 26/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6244308.5000 - mse: 6244291.0000\n",
            "Epoch 27/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6253298.5000 - mse: 6253278.5000\n",
            "Epoch 28/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6235892.5000 - mse: 6235870.5000\n",
            "Epoch 29/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 6218596.5000 - mse: 6218578.5000\n",
            "Epoch 30/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 6206411.5000 - mse: 6206395.0000\n",
            "Epoch 31/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 6224690.0000 - mse: 6224669.5000\n",
            "Epoch 32/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 6182138.5000 - mse: 6182119.5000\n",
            "Epoch 33/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6209562.5000 - mse: 6209542.5000\n",
            "Epoch 34/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 6189627.5000 - mse: 6189602.5000\n",
            "Epoch 35/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6186332.0000 - mse: 6186311.5000\n",
            "Epoch 36/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6166379.5000 - mse: 6166354.0000\n",
            "Epoch 37/200\n",
            "18176/18176 [==============================] - 64s 3ms/step - loss: 6170919.5000 - mse: 6170899.0000\n",
            "Epoch 38/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6171779.0000 - mse: 6171761.0000\n",
            "Epoch 39/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 6156459.5000 - mse: 6156438.0000\n",
            "Epoch 40/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6148237.0000 - mse: 6148214.0000\n",
            "Epoch 41/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6155477.5000 - mse: 6155448.5000\n",
            "Epoch 42/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6144235.0000 - mse: 6144211.5000\n",
            "Epoch 43/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6124311.5000 - mse: 6124284.0000\n",
            "Epoch 44/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6119672.5000 - mse: 6119643.5000\n",
            "Epoch 45/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6122210.0000 - mse: 6122178.0000\n",
            "Epoch 46/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6114756.0000 - mse: 6114731.0000\n",
            "Epoch 47/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6110636.5000 - mse: 6110610.5000\n",
            "Epoch 48/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6097420.5000 - mse: 6097393.5000\n",
            "Epoch 49/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6089436.0000 - mse: 6089412.0000\n",
            "Epoch 50/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6083354.0000 - mse: 6083318.0000\n",
            "Epoch 51/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6080413.5000 - mse: 6080385.0000\n",
            "Epoch 52/200\n",
            "18176/18176 [==============================] - 60s 3ms/step - loss: 6080444.0000 - mse: 6080415.5000\n",
            "Epoch 53/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6072992.0000 - mse: 6072959.0000\n",
            "Epoch 54/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 6076128.0000 - mse: 6076092.0000\n",
            "Epoch 55/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6060700.0000 - mse: 6060672.5000\n",
            "Epoch 56/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6061454.0000 - mse: 6061424.5000\n",
            "Epoch 57/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6055458.0000 - mse: 6055427.0000\n",
            "Epoch 58/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6063133.5000 - mse: 6063102.0000\n",
            "Epoch 59/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6046344.5000 - mse: 6046311.0000\n",
            "Epoch 60/200\n",
            "18176/18176 [==============================] - 59s 3ms/step - loss: 6052117.5000 - mse: 6052083.0000\n",
            "Epoch 61/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 6036913.0000 - mse: 6036873.0000\n",
            "Epoch 62/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6038115.0000 - mse: 6038079.5000\n",
            "Epoch 63/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 6040455.5000 - mse: 6040416.5000\n",
            "Epoch 64/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6037258.5000 - mse: 6037217.5000\n",
            "Epoch 65/200\n",
            "18176/18176 [==============================] - 60s 3ms/step - loss: 6032075.5000 - mse: 6032035.0000\n",
            "Epoch 66/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6022465.5000 - mse: 6022429.5000\n",
            "Epoch 67/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 6015681.0000 - mse: 6015650.0000\n",
            "Epoch 68/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 6003940.5000 - mse: 6003899.5000\n",
            "Epoch 69/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 6009650.5000 - mse: 6009609.5000\n",
            "Epoch 70/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 6010178.0000 - mse: 6010139.0000\n",
            "Epoch 71/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5996331.0000 - mse: 5996287.0000\n",
            "Epoch 72/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5991596.5000 - mse: 5991556.5000\n",
            "Epoch 73/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5993065.0000 - mse: 5993025.5000\n",
            "Epoch 74/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5988078.5000 - mse: 5988038.5000\n",
            "Epoch 75/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 5975418.0000 - mse: 5975381.0000\n",
            "Epoch 76/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5982465.0000 - mse: 5982421.5000\n",
            "Epoch 77/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5985517.0000 - mse: 5985479.5000\n",
            "Epoch 78/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5981871.0000 - mse: 5981828.5000\n",
            "Epoch 79/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5960368.5000 - mse: 5960324.5000\n",
            "Epoch 80/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5963621.0000 - mse: 5963583.0000\n",
            "Epoch 81/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5959240.5000 - mse: 5959191.0000\n",
            "Epoch 82/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5958193.0000 - mse: 5958151.0000\n",
            "Epoch 83/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 5957585.0000 - mse: 5957539.0000\n",
            "Epoch 84/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5944886.0000 - mse: 5944840.5000\n",
            "Epoch 85/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5945161.5000 - mse: 5945114.5000\n",
            "Epoch 86/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5934520.5000 - mse: 5934480.0000\n",
            "Epoch 87/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 5930386.5000 - mse: 5930342.5000\n",
            "Epoch 88/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5936287.5000 - mse: 5936241.5000\n",
            "Epoch 89/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5927753.5000 - mse: 5927709.0000\n",
            "Epoch 90/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5930735.0000 - mse: 5930687.0000\n",
            "Epoch 91/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5912647.0000 - mse: 5912599.0000\n",
            "Epoch 92/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5921908.5000 - mse: 5921858.0000\n",
            "Epoch 93/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5921400.5000 - mse: 5921352.0000\n",
            "Epoch 94/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5905068.0000 - mse: 5905025.0000\n",
            "Epoch 95/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5914379.5000 - mse: 5914326.0000\n",
            "Epoch 96/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5904666.0000 - mse: 5904619.0000\n",
            "Epoch 97/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5893718.0000 - mse: 5893675.0000\n",
            "Epoch 98/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5899222.5000 - mse: 5899170.5000\n",
            "Epoch 99/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5901730.5000 - mse: 5901679.5000\n",
            "Epoch 100/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5900961.0000 - mse: 5900910.0000\n",
            "Epoch 101/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5880949.0000 - mse: 5880893.5000\n",
            "Epoch 102/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5900598.0000 - mse: 5900552.5000\n",
            "Epoch 103/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5876447.5000 - mse: 5876398.0000\n",
            "Epoch 104/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5866720.5000 - mse: 5866668.5000\n",
            "Epoch 105/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5876923.5000 - mse: 5876870.5000\n",
            "Epoch 106/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5879033.5000 - mse: 5878982.0000\n",
            "Epoch 107/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5866030.5000 - mse: 5865977.5000\n",
            "Epoch 108/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5865800.0000 - mse: 5865744.5000\n",
            "Epoch 109/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5874405.5000 - mse: 5874351.0000\n",
            "Epoch 110/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5862882.0000 - mse: 5862824.0000\n",
            "Epoch 111/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5858329.5000 - mse: 5858279.0000\n",
            "Epoch 112/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5849762.0000 - mse: 5849705.0000\n",
            "Epoch 113/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5857211.5000 - mse: 5857154.5000\n",
            "Epoch 114/200\n",
            "18176/18176 [==============================] - 60s 3ms/step - loss: 5843412.0000 - mse: 5843361.0000\n",
            "Epoch 115/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5853762.0000 - mse: 5853711.0000\n",
            "Epoch 116/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5833456.5000 - mse: 5833402.5000\n",
            "Epoch 117/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5857218.5000 - mse: 5857163.5000\n",
            "Epoch 118/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5827470.5000 - mse: 5827412.0000\n",
            "Epoch 119/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5831998.0000 - mse: 5831949.0000\n",
            "Epoch 120/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5830735.5000 - mse: 5830675.5000\n",
            "Epoch 121/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5840525.5000 - mse: 5840465.0000\n",
            "Epoch 122/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5820212.5000 - mse: 5820157.5000\n",
            "Epoch 123/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5808190.5000 - mse: 5808131.0000\n",
            "Epoch 124/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5831808.0000 - mse: 5831756.0000\n",
            "Epoch 125/200\n",
            "18176/18176 [==============================] - 72s 4ms/step - loss: 5811907.0000 - mse: 5811846.5000\n",
            "Epoch 126/200\n",
            "18176/18176 [==============================] - 72s 4ms/step - loss: 5807837.5000 - mse: 5807777.5000\n",
            "Epoch 127/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5814682.5000 - mse: 5814618.0000\n",
            "Epoch 128/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5796559.0000 - mse: 5796492.5000\n",
            "Epoch 129/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5803006.5000 - mse: 5802944.0000\n",
            "Epoch 130/200\n",
            "18176/18176 [==============================] - 72s 4ms/step - loss: 5800880.5000 - mse: 5800819.5000\n",
            "Epoch 131/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5788091.0000 - mse: 5788026.0000\n",
            "Epoch 132/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5803577.0000 - mse: 5803513.5000\n",
            "Epoch 133/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5800428.0000 - mse: 5800375.5000\n",
            "Epoch 134/200\n",
            "18176/18176 [==============================] - 73s 4ms/step - loss: 5787922.0000 - mse: 5787865.5000\n",
            "Epoch 135/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5782736.5000 - mse: 5782664.5000\n",
            "Epoch 136/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5786195.0000 - mse: 5786132.5000\n",
            "Epoch 137/200\n",
            "18176/18176 [==============================] - 73s 4ms/step - loss: 5791352.0000 - mse: 5791288.5000\n",
            "Epoch 138/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5785883.0000 - mse: 5785816.5000\n",
            "Epoch 139/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5781338.5000 - mse: 5781271.5000\n",
            "Epoch 140/200\n",
            "18176/18176 [==============================] - 69s 4ms/step - loss: 5773082.5000 - mse: 5773018.0000\n",
            "Epoch 141/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5782202.5000 - mse: 5782144.0000\n",
            "Epoch 142/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5758999.5000 - mse: 5758934.0000\n",
            "Epoch 143/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5767489.0000 - mse: 5767431.0000\n",
            "Epoch 144/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5751570.0000 - mse: 5751505.5000\n",
            "Epoch 145/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5755760.0000 - mse: 5755686.5000\n",
            "Epoch 146/200\n",
            "18176/18176 [==============================] - 72s 4ms/step - loss: 5757422.0000 - mse: 5757356.0000\n",
            "Epoch 147/200\n",
            "18176/18176 [==============================] - 73s 4ms/step - loss: 5735042.0000 - mse: 5734976.5000\n",
            "Epoch 148/200\n",
            "18176/18176 [==============================] - 71s 4ms/step - loss: 5753840.5000 - mse: 5753773.5000\n",
            "Epoch 149/200\n",
            "18176/18176 [==============================] - 70s 4ms/step - loss: 5737286.5000 - mse: 5737218.0000\n",
            "Epoch 150/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5751840.5000 - mse: 5751768.5000\n",
            "Epoch 151/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5746977.5000 - mse: 5746912.5000\n",
            "Epoch 152/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5727632.5000 - mse: 5727567.5000\n",
            "Epoch 153/200\n",
            "18176/18176 [==============================] - 60s 3ms/step - loss: 5738444.0000 - mse: 5738376.0000\n",
            "Epoch 154/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 5733787.0000 - mse: 5733724.0000\n",
            "Epoch 155/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5731765.5000 - mse: 5731701.5000\n",
            "Epoch 156/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5732568.5000 - mse: 5732492.5000\n",
            "Epoch 157/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5727993.5000 - mse: 5727922.5000\n",
            "Epoch 158/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5723059.0000 - mse: 5722992.0000\n",
            "Epoch 159/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5715156.0000 - mse: 5715085.0000\n",
            "Epoch 160/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5714496.5000 - mse: 5714421.0000\n",
            "Epoch 161/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5716998.0000 - mse: 5716925.5000\n",
            "Epoch 162/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5715375.0000 - mse: 5715305.0000\n",
            "Epoch 163/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 5708459.5000 - mse: 5708382.0000\n",
            "Epoch 164/200\n",
            "18176/18176 [==============================] - 61s 3ms/step - loss: 5697036.5000 - mse: 5696967.0000\n",
            "Epoch 165/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5714139.0000 - mse: 5714061.0000\n",
            "Epoch 166/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5702770.5000 - mse: 5702701.0000\n",
            "Epoch 167/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5705803.0000 - mse: 5705731.0000\n",
            "Epoch 168/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5697528.0000 - mse: 5697453.5000\n",
            "Epoch 169/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5695284.5000 - mse: 5695210.5000\n",
            "Epoch 170/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5683827.0000 - mse: 5683753.5000\n",
            "Epoch 171/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5686162.0000 - mse: 5686096.5000\n",
            "Epoch 172/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5688867.0000 - mse: 5688792.5000\n",
            "Epoch 173/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5682966.5000 - mse: 5682889.0000\n",
            "Epoch 174/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5694513.5000 - mse: 5694442.0000\n",
            "Epoch 175/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5685748.0000 - mse: 5685682.5000\n",
            "Epoch 176/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5684117.5000 - mse: 5684042.0000\n",
            "Epoch 177/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5682407.0000 - mse: 5682343.0000\n",
            "Epoch 178/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5667069.5000 - mse: 5666995.0000\n",
            "Epoch 179/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5666045.5000 - mse: 5665966.5000\n",
            "Epoch 180/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5671400.5000 - mse: 5671325.5000\n",
            "Epoch 181/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5663934.5000 - mse: 5663855.5000\n",
            "Epoch 182/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5667365.5000 - mse: 5667288.0000\n",
            "Epoch 183/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5659399.0000 - mse: 5659327.5000\n",
            "Epoch 184/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5655228.5000 - mse: 5655161.5000\n",
            "Epoch 185/200\n",
            "18176/18176 [==============================] - 64s 3ms/step - loss: 5663897.0000 - mse: 5663829.0000\n",
            "Epoch 186/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5649831.0000 - mse: 5649758.0000\n",
            "Epoch 187/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5651557.0000 - mse: 5651480.0000\n",
            "Epoch 188/200\n",
            "18176/18176 [==============================] - 67s 4ms/step - loss: 5637466.5000 - mse: 5637396.0000\n",
            "Epoch 189/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5633521.0000 - mse: 5633440.5000\n",
            "Epoch 190/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5641437.5000 - mse: 5641365.0000\n",
            "Epoch 191/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5639908.0000 - mse: 5639828.5000\n",
            "Epoch 192/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5648607.5000 - mse: 5648528.0000\n",
            "Epoch 193/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5629891.0000 - mse: 5629814.5000\n",
            "Epoch 194/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5635765.5000 - mse: 5635690.5000\n",
            "Epoch 195/200\n",
            "18176/18176 [==============================] - 66s 4ms/step - loss: 5628691.5000 - mse: 5628618.5000\n",
            "Epoch 196/200\n",
            "18176/18176 [==============================] - 65s 4ms/step - loss: 5613267.5000 - mse: 5613179.5000\n",
            "Epoch 197/200\n",
            "18176/18176 [==============================] - 63s 3ms/step - loss: 5627100.0000 - mse: 5627019.0000\n",
            "Epoch 198/200\n",
            "18176/18176 [==============================] - 64s 4ms/step - loss: 5637196.0000 - mse: 5637116.0000\n",
            "Epoch 199/200\n",
            "18176/18176 [==============================] - 62s 3ms/step - loss: 5631542.5000 - mse: 5631457.0000\n",
            "Epoch 200/200\n",
            "18176/18176 [==============================] - 68s 4ms/step - loss: 5616395.5000 - mse: 5616328.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zESRMy8X5giH"
      },
      "source": [
        "predict = model.predict(x_test)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzlUTBEhiPPi"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFdGvLXoiS1G",
        "outputId": "a8b7bf43-be46-4ee5-ff35-b39a7ce78fcb"
      },
      "source": [
        "# Print the results of MAE\r\n",
        "print(np.sqrt(metrics.mean_absolute_error(y_test, predict)))\r\n",
        "\r\n",
        "# Print the results of MSE\r\n",
        "print(metrics.mean_squared_error(y_test, predict))\r\n",
        "\r\n",
        "# Print the results of RMSE\r\n",
        "print(np.sqrt(metrics.mean_squared_error(y_test, predict)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40.21948486865622\n",
            "4483046.168513649\n",
            "2117.320516245391\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}